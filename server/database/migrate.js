const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');
require('dotenv').config();

const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: process.env.DB_PORT || 5432,
  database: process.env.DB_NAME || 'pesz_db',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD,
});

async function runMigrations() {
  const client = await pool.connect();
  
  try {
    console.log('ðŸš€ Starting database migrations...');
    
    // Read and execute schema.sql
    const schemaPath = path.join(__dirname, 'schema.sql');
    const schemaSQL = fs.readFileSync(schemaPath, 'utf8');
    
    console.log('ðŸ“‹ Executing schema migrations...');
    await client.query(schemaSQL);
    console.log('âœ… Schema migrations completed successfully!');
    
    // Ask if user wants to run seed data
    if (process.argv.includes('--seed')) {
      console.log('ðŸŒ± Running seed data...');
      const seedPath = path.join(__dirname, 'seed.sql');
      const seedSQL = fs.readFileSync(seedPath, 'utf8');
      
      await client.query(seedSQL);
      console.log('âœ… Seed data inserted successfully!');
    }
    
    console.log('ðŸŽ‰ Database setup completed!');
    
  } catch (error) {
    console.error('âŒ Migration failed:', error);
    throw error;
  } finally {
    client.release();
    await pool.end();
  }
}

// Run migrations if this file is executed directly
if (require.main === module) {
  runMigrations()
    .then(() => {
      console.log('Migration completed successfully');
      process.exit(0);
    })
    .catch((error) => {
      console.error('Migration failed:', error);
      process.exit(1);
    });
}

module.exports = { runMigrations };